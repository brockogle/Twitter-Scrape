{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Twitter API\n",
    "##### By Michael Carlin and Brock Ogle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from requests_oauthlib import OAuth1\n",
    "import requests\n",
    "import webbrowser\n",
    "#import the currently required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loads the consumer and access tokens generated in Notebook1\n",
    "with open('tokens1.json') as f:\n",
    "    tokens = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieves consumer and access tokens from json file\n",
    "consumer_key = tokens['consumer']['consumer_key']\n",
    "consumer_secret = tokens['consumer']['consumer_secret']\n",
    "access_token = tokens['access_token']['access_token']\n",
    "access_token_secret = tokens['access_token']['access_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Establishes a common beginning and ending to request url to avoid repitition\n",
    "base = 'https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name='\n",
    "end = '&count=200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auth_check(auth):\n",
    "    '''\n",
    "    This function checks if the access token is still valid. If valid the function\n",
    "    returns the valid authorization, if not the function prompts the user to refresh\n",
    "    their access token via Notebook1\n",
    "    \n",
    "    Parameters:\n",
    "        auth - current consumer and access token\n",
    "        \n",
    "    Return:\n",
    "        auth - valid consumer and access token\n",
    "    '''\n",
    "    #URL provided by twitter for checking validity of authorization credentials\n",
    "    url = 'https://api.twitter.com/1.1/account/verify_credentials.json'\n",
    "    #Establishes current authorization via requests_oauthlib module\n",
    "    auth = OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "    response = requests.get(url, auth=auth)     #Uses GET to get response code\n",
    "    if str(response) == '<Response [200]>':     #Checks status of response code\n",
    "        return auth\n",
    "    else:\n",
    "        print 'access token is invalid'\n",
    "        print 'please visit Notebook1 and run to completion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_tweets(id,n,auth):\n",
    "    '''\n",
    "    This functions appends tweets to a list after a users first 200 tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        id - The eariest possible tweet to retrieve data from\n",
    "        n - recursive number to stop the collection of data\n",
    "        auth - valid consumer and access tokens\n",
    "        \n",
    "    Return:\n",
    "        id - earliest possible tweet for next iteration of next_tweets function\n",
    "        n - recursive count, decreased by 1 level before returning\n",
    "    '''\n",
    "    #uses &max_id parameter to collect next 200 tweets\n",
    "    new_endpoint = base+user+'&max_id='+str(id)\n",
    "    r = requests.get(new_endpoint,auth=auth)   #data from specified endpoint\n",
    "    tweets1 = r.json()                         #converts data to json format\n",
    "    for tweet in tweets1:\n",
    "        tweeets.append(tweet['text'])          #appends contents of each tweet to list\n",
    "    id = tweet['id'] - 1                       #sets earliest tweet for next iteration \n",
    "    n = n-1                                    #decreases recursive level by 1\n",
    "    return id, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_bridge(n,id,auth):\n",
    "    '''\n",
    "    This recursive function houses the next_tweets call in order to avoid the problem of\n",
    "    the earliest tweet id not properly resetting if next_tweets was called in for loop\n",
    "    \n",
    "    Parameters:\n",
    "        id - The eariest possible tweet to retrieve data from\n",
    "        n - recursive number to stop the collection of data\n",
    "        auth - valid consumer and access tokens\n",
    "        \n",
    "    Return:\n",
    "        Function exits if level is 0\n",
    "    '''\n",
    "    if n >=1:                             #checks level\n",
    "        id, n = next_tweets(id,n,auth)    #appends next 200 tweets to list\n",
    "        tweet_bridge(n,id,auth)           #recursive call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_tweets(n,auth, timeline_endpoint):\n",
    "    '''\n",
    "    This function appends the contents of a users first 200 tweets to a list and calls\n",
    "    the function necessary to extract further tweets\n",
    "    \n",
    "    Parameters:\n",
    "        n - recursive number to stop the collection of data\n",
    "        auth - valid consumer and access tokens\n",
    "        timeline_endpoint - initial endpoint to extract data\n",
    "        \n",
    "    Return:\n",
    "        calls tweet_bridge() function\n",
    "    '''\n",
    "    r = requests.get(timeline_endpoint, auth=auth)   #data from user's timeline\n",
    "    tweets = r.json()                                #puts data in json format\n",
    "    for tweet in tweets:\n",
    "        tweeets.append(tweet['text'])               #adds contents of tweet to list\n",
    "    id = tweet['id'] - 1                            #sets earliest next tweet\n",
    "    tweet_bridge(n,id,auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_create(list,counts,hash_count):\n",
    "    '''This calls function necessary to create a dictionary of word frequency counts.\n",
    "    \n",
    "    Parameters:\n",
    "        list - contents of all tweets\n",
    "        counts - empty dictionary\n",
    "        auth - empty dictionary\n",
    "        \n",
    "    Return:\n",
    "        calls word_count function for tweet in list of tweets\n",
    "    '''\n",
    "    for item in list:\n",
    "        word_count(item,counts,hash_count)        #calls counter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_count(str,counts,hash_count):\n",
    "    '''\n",
    "    This function splits text of each tweet and counts individual words,\n",
    "    excluding any non alphanumeric characters\n",
    "    \n",
    "    Parameters:\n",
    "        str - The text of each tweet\n",
    "        counts - dictionary counter of words in a user's tweets\n",
    "        hash_counts - dictionary counter of hashtags in user's tweets\n",
    "        \n",
    "    Return:\n",
    "        None\n",
    "    '''\n",
    "    words = str.split()                      #splits text of tweet on whitespace\n",
    "    for word in words:\n",
    "        word = word.lower()                  #Eliminates miscounts due to capitalization\n",
    "        regex = re.compile('[^a-z0-9\\#]')    #Sets regular expression to only alphanumerics\n",
    "        word = regex.sub('',word)            #Each word now only consists of alphanumerics\n",
    "        if word == '':                       #takes care of words with no alphanumerics\n",
    "            word = 'NoAlphanumericCharacters'\n",
    "        if word[0] == '#':                  #counts users hashtags\n",
    "            if word in hash_count:\n",
    "                hash_count[word] += 1      #appends count\n",
    "            else:\n",
    "                hash_count[word] = 1       #starts new count\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        if word not in counts and word[0:4] != 'http':  #eliminates hyperlinks to pictures\n",
    "            counts[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_ready(dict):\n",
    "    '''\n",
    "    This function strips the contents of a dictionary into two equal length lists\n",
    "    to be used in a Pandas DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "        dict - dictionary to be split\n",
    "        \n",
    "    Return:\n",
    "        list_word - list of all words\n",
    "        list_count - list of frequency of all words\n",
    "    '''\n",
    "    list_word = []       #blank list\n",
    "    list_count = []\n",
    "    for item in dict:\n",
    "        list_word.append(item)        #appends words to list\n",
    "        list_count.append(dict[item]) #appends frequencies to list\n",
    "    return list_word, list_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retweet_finder(auth,endpoint):\n",
    "    '''\n",
    "    This function creates lists with times, number of retweets, and number\n",
    "    of favorites for each user's original tweets. This function also \n",
    "    removes all retweeted, unoriginal content from consideration.\n",
    "    \n",
    "    Parameters:\n",
    "        auth - valid authorization credentials\n",
    "        endpoint - endpoint to access data\n",
    "        \n",
    "    Return:\n",
    "        times_list - time and data of each tweet\n",
    "        rt_list - number of retweets for each tweet\n",
    "        fav_list - number of favorites for each tweet\n",
    "    '''\n",
    "    times_list = []     #empty list\n",
    "    rt_list = []\n",
    "    fav_list = []\n",
    "    r = requests.get(timeline_endpoint, auth=auth)   #gets data from endpoint\n",
    "    tweets = r.json()                                #converts data to json format\n",
    "    for tweet in tweets:\n",
    "        if tweet['favorite_count'] != 0:             #filters unoriginal content\n",
    "            created_at = tweet['created_at']         #reformats dates and times to\n",
    "            created_at2 = created_at[4:19]           #be used in Tableau later\n",
    "            if created_at2[:3] == 'Dec':\n",
    "                created_at1 = '12/'+ created_at2[4:6]+'/2017 '+created_at2[7:]\n",
    "            else:\n",
    "                created_at1 = '11/'+ created_at2[4:6]+'/2017 '+created_at2[7:]\n",
    "            times_list.append(created_at1)           #append respective lists\n",
    "            rt_list.append(tweet['retweet_count'])\n",
    "            fav_list.append(tweet['favorite_count'])\n",
    "    return times_list, rt_list, fav_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#establishes original valid authorization credentials\n",
    "url = 'https://api.twitter.com/1.1/account/verify_credentials.json'\n",
    "auth = OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "auth = auth_check(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'realDonaldTrump'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "TRUMP_count = {}\n",
    "TRUMP_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,TRUMP_count,TRUMP_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "TRUMP_list_word, TRUMP_list_count = df_ready(TRUMP_count)\n",
    "df_TRUMP_count = pd.DataFrame({'word':TRUMP_list_word,'freq':TRUMP_list_count})\n",
    "TRUMP_list_hash, TRUMP_list_hash_count = df_ready(TRUMP_hash_count)\n",
    "df_TRUMP_hash = pd.DataFrame({'word':TRUMP_list_hash,'freq':TRUMP_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_TRUMP_count['user'] = 'Trump'\n",
    "df_TRUMP_hash['user'] = 'Trump'\n",
    "\n",
    "#Creates popularity data\n",
    "timeline_endpoint = base+user+end\n",
    "TRUMP_times_list, TRUMP_rt_list, TRUMP_fav_list = retweet_finder(auth,timeline_endpoint)\n",
    "\n",
    "#Creates popularity DataFrames and sets extra identifier variable\n",
    "df_TRUMP_popular = pd.DataFrame({'created_at':TRUMP_times_list,\n",
    "                                 'rt_count':TRUMP_rt_list,\n",
    "                                 'fav_count':TRUMP_fav_list})\n",
    "df_TRUMP_popular['user'] = 'Trump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'gop'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "GOP_count = {}\n",
    "GOP_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,GOP_count,GOP_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "GOP_list_word, GOP_list_count = df_ready(GOP_count)\n",
    "df_GOP_count = pd.DataFrame({'word':GOP_list_word,'freq':GOP_list_count})\n",
    "GOP_list_hash, GOP_list_hash_count = df_ready(GOP_hash_count)\n",
    "df_GOP_hash = pd.DataFrame({'word':GOP_list_hash,'freq':GOP_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_GOP_count['user'] = 'GOP'\n",
    "df_GOP_hash['user'] = 'GOP'\n",
    "\n",
    "#Creates popularity data\n",
    "timeline_endpoint = base+user+end\n",
    "GOP_times_list, GOP_rt_list, GOP_fav_list = retweet_finder(auth,timeline_endpoint)\n",
    "\n",
    "#Creates popularity DataFrames and sets extra identifier variable\n",
    "df_GOP_popular = pd.DataFrame({'created_at':GOP_times_list,\n",
    "                               'rt_count':GOP_rt_list,\n",
    "                               'fav_count':GOP_fav_list})\n",
    "df_GOP_popular['user'] = 'GOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'theDemocrats'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "DEM_count = {}\n",
    "DEM_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,DEM_count,DEM_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "DEM_list_word, DEM_list_count = df_ready(DEM_count)\n",
    "df_DEM_count = pd.DataFrame({'word':DEM_list_word,'freq':DEM_list_count})\n",
    "DEM_list_hash, DEM_list_hash_count = df_ready(DEM_hash_count)\n",
    "df_DEM_hash = pd.DataFrame({'word':DEM_list_hash,'freq':DEM_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_DEM_count['user'] = 'DEM'\n",
    "df_DEM_hash['user'] = 'DEM'\n",
    "\n",
    "#Creates popularity data\n",
    "timeline_endpoint = base+user+end\n",
    "DEM_times_list, DEM_rt_list, DEM_fav_list = retweet_finder(auth,timeline_endpoint)\n",
    "\n",
    "#Creates popularity DataFrames and sets extra identifier variable\n",
    "df_DEM_popular = pd.DataFrame({'created_at':DEM_times_list,\n",
    "                               'rt_count':DEM_rt_list,\n",
    "                               'fav_count':DEM_fav_list})\n",
    "df_DEM_popular['user'] = 'DEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'HouseDemocrats'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "HouseDEM_count = {}\n",
    "HouseDEM_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,HouseDEM_count,HouseDEM_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "HouseDEM_list_word, HouseDEM_list_count = df_ready(HouseDEM_count)\n",
    "df_HouseDEM_count = pd.DataFrame({'word':HouseDEM_list_word,'freq':HouseDEM_list_count})\n",
    "HouseDEM_list_hash, HouseDEM_list_hash_count = df_ready(HouseDEM_hash_count)\n",
    "df_HouseDEM_hash = pd.DataFrame({'word':HouseDEM_list_hash,'freq':HouseDEM_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_HouseDEM_count['user'] = 'DEM'\n",
    "df_HouseDEM_hash['user'] = 'DEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'HouseGOP'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "HouseGOP_count = {}\n",
    "HouseGOP_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,HouseGOP_count,HouseGOP_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "HouseGOP_list_word, HouseGOP_list_count = df_ready(HouseGOP_count)\n",
    "df_HouseGOP_count = pd.DataFrame({'word':HouseGOP_list_word,'freq':HouseGOP_list_count})\n",
    "HouseGOP_list_hash, HouseGOP_list_hash_count = df_ready(HouseGOP_hash_count)\n",
    "df_HouseGOP_hash = pd.DataFrame({'word':HouseGOP_list_hash,'freq':HouseGOP_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_HouseGOP_count['user'] = 'GOP'\n",
    "df_HouseGOP_hash['user'] = 'GOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'SenateGOP'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "SenateGOP_count = {}\n",
    "SenateGOP_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,SenateGOP_count,SenateGOP_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "SenateGOP_list_word, SenateGOP_list_count = df_ready(SenateGOP_count)\n",
    "df_SenateGOP_count = pd.DataFrame({'word':SenateGOP_list_word,'freq':SenateGOP_list_count})\n",
    "SenateGOP_list_hash, SenateGOP_list_hash_count = df_ready(SenateGOP_hash_count)\n",
    "df_SenateGOP_hash = pd.DataFrame({'word':SenateGOP_list_hash,'freq':SenateGOP_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_SenateGOP_count['user'] = 'GOP'\n",
    "df_SenateGOP_hash['user'] = 'GOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks credentials, sets user and original endpoint\n",
    "auth = auth_check(auth)\n",
    "user = 'SenateDems'\n",
    "timeline_endpoint = base+user+end\n",
    "\n",
    "#creates initial empty dictionary and resets tweeets list\n",
    "tweeets = []\n",
    "SenateDEM_count = {}\n",
    "SenateDEM_hash_count = {}\n",
    "\n",
    "#Call functions to create counts of each word/hashtag in tweets\n",
    "all_tweets(15,auth,timeline_endpoint)\n",
    "dict_create(tweeets,SenateDEM_count,SenateDEM_hash_count)\n",
    "\n",
    "#Creates DataFrames to later be merged/exported\n",
    "SenateDEM_list_word, SenateDEM_list_count = df_ready(SenateDEM_count)\n",
    "df_SenateDEM_count = pd.DataFrame({'word':SenateDEM_list_word,'freq':SenateDEM_list_count})\n",
    "SenateDEM_list_hash, SenateDEM_list_hash_count = df_ready(SenateDEM_hash_count)\n",
    "df_SenateDEM_hash = pd.DataFrame({'word':SenateDEM_list_hash,'freq':SenateDEM_list_hash_count})\n",
    "\n",
    "#Sets extra variable for Tableau analysis\n",
    "df_SenateDEM_count['user'] = 'DEM'\n",
    "df_SenateDEM_hash['user'] = 'DEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combines selected DataFrames for easier Tableau analysis\n",
    "#Exports combined DataFrame to a .csv file\n",
    "frames_popular = [df_TRUMP_popular,df_GOP_popular,df_DEM_popular]\n",
    "df_popular = pd.concat(frames_popular)\n",
    "df_popular.to_csv('popular.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combines selected DataFrames for easier Tableau analysis\n",
    "#Exports combined DataFrame to a .csv file\n",
    "frames_popular_Trumpless = [df_GOP_popular,df_DEM_popular]\n",
    "df_popular_Trumpless = pd.concat(frames_popular_Trumpless)\n",
    "df_popular_Trumpless.to_csv('popular_Trumpless.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combines selected DataFrames for easier Tableau analysis\n",
    "#Exports combined DataFrame to a .csv file\n",
    "frames_house = [df_HouseDEM_count,df_HouseGOP_count]\n",
    "df_house = pd.concat(frames_house)\n",
    "df_house.to_csv('house_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combines selected DataFrames for easier Tableau analysis\n",
    "#Exports combined DataFrame to a .csv file\n",
    "frames_senate = [df_SenateDEM_count,df_SenateGOP_count]\n",
    "df_senate = pd.concat(frames_senate)\n",
    "df_senate.to_csv('senate_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combines selected DataFrames for easier Tableau analysis\n",
    "#Exports combined DataFrame to a .csv file\n",
    "frames_all = [df_DEM_count,df_GOP_count,df_TRUMP_count]\n",
    "df_all = pd.concat(frames_all)\n",
    "df_all.to_csv('all_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combines selected DataFrames for easier Tableau analysis\n",
    "#Exports combined DataFrame to a .csv file\n",
    "frames_all_hash = [df_DEM_hash,df_GOP_hash,df_TRUMP_hash]\n",
    "df_all_hash = pd.concat(frames_all_hash)\n",
    "df_all_hash.to_csv('all_hash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
